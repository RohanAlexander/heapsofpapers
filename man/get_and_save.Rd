% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_and_save.R
\name{get_and_save}
\alias{get_and_save}
\title{get_these_and_save_them}
\usage{
get_and_save(
  data,
  links = "links",
  save_names = "save_names",
  dir = ".",
  bucket = NULL,
  delay = 5
)
}
\arguments{
\item{data}{A dataframe that contains URLs that you want to download and the names
that you want to save them as.}

\item{links}{The name of the column whose values should be the URLs that you
want to download, \code{link_pdf} by default.}

\item{save_names}{The name of the column whose values should be the saved
file names where the downloaded file will be saved, \code{id} by default.}

\item{dir}{The directory to download files to, defaults to current working directory.}

\item{bucket}{name of AWS S3 bucket to save files to.}

\item{delay}{The number of seconds to wait between downloads, default (and
minimum) is five seconds. We automatically add a bit of noise to lessen the effect
on systematic processes that might be otherwise working.}
}
\description{
The \code{get_and_save} function works with a tibble of
locations (usually URLs) and file names, and then downloads the PDF from the
location to the file name, saving as it goes, and letting you know where it's
up to. It politely waits around 7 seconds between calls to the
location, and skips locations that give an error.
}
\examples{
\dontrun{two_pdfs <-
tibble::tibble(
  locations_are = c("https://osf.io/preprints/socarxiv/z4qg9/download",
                    "https://osf.io/preprints/socarxiv/a29h8/download"),
  save_here = c("competing_effects_on_the_average_age_of_infant_death.pdf",
                "cesr_an_r_package_for_the_canadian_election_study.pdf")
)

heapsofpapers::get_and_save(
data = two_pdfs,
links = "locations_are",
save_names = "save_here"
)
}
}
